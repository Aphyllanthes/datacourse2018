---
title: "Advanced SQL techniques"
author: "Mirko Mälicke"
output:
  html_document:
    df_print: paged
    theme: flatly
    toc: yes
    toc_float: yes
  html_notebook:
    number_sections: yes
    theme: flatly
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r, include=FALSE}
# require the package
if (!("RPostgreSQL" %in% installed.packages())){
  install.packages("RPostgreSQL")
}
if (!("getPass" %in% installed.packages())){
  install.packages("getPass")
}
require(RPostgreSQL)
require(getPass)
require(ggplot2)
require(dplyr)

# establish the connection
drv <- dbDriver('PostgreSQL')
con <- dbConnect(drv, host='openhydro.de', port=5432, user=getPass('Provide the user'), 
                 password=getPass('Provide the password'), dbname='dwd')
```

# Temporarily creating objects

Especially for development and data analysis tasks it is very useful to create temporary results. This saves a lot of time and will keep
 your database clean as you do not have to remember which objects were only intermediate and can be droped.
The SQL language knows the <span style="color:blue">TEMPORARY</span> keyword, which can be used along with <span style="color:blue">CREATE</span> statements. 
This is most often used on the creation of tables and views. The temporary tables can be used just like persistent tables, but once you close the 
connection used for creation, the table will automatically be droped. 
This can save you from a lot of cleanup work. 

<div class="alert alert-warning">Some SQL clients open and close a connection on each command issued in order to keep the number of connection small and
prevent the user from keeping open connections. You will have to change the settings or the tool in case you want to use temporary object using these tools.</div>
<hr>
There is a table called *bw_temp_2017b* in the database. This table includes daily meteorological measurements as distributed by the DWD for temperature, rainfall, snowfall and relative humidity. 
The database table is saved just like it was imorted. The table _data_ is a more normalized version of the first one. A temporary table can be useful to 
extract only the parameters needed from the normalized table. Let's have a look at it.

```{sql connection=con}
select * from data order by id, date DESC limit 10
```

As you can see, there are different values for the same day at the same station. The meaning of this value is described in a lookup table joined by the variable id. 
This structure might feel strange but is very common to save timeseries data. It is performat, flexible and easy to maintain and extend. 
These advantages come at the tradeoff of a bit more complex structure and hence more complicated queries. 
But one step after the other. Let's have a look at the lookup table.

```{sql connection=con}
select * from variables
```

This is a quite small lookup table, but as you can see we do not have to write the full name of the variable behind every entry in the data table.
The brings us way more flexibility in describing the variables. At the end of the day both tables be joined togehter quite easy.<br>

Imagine we only want to use the precipitation values today, we can build a new temporary table as a starting point.

```{sql connection=con}
create temporary table precipitation as
select id, date, value as precipitation from data where variable_id=1
```
```{sql connection=con}
select * from precipitation limit 5
```

The next structure we want to use is the view. A view is like a persistant <span style="color: blue">SELECT</span> query that will be rerun each time you try to query the results. 
It will behave like a dynamic table with the only difference of being not editable. From a performance point of view, a view is not capable of indices, which can make it way slower than a table. <br>
Let's create a view of monthly min, max, mean, and count of precipitation.

```{sql connection=con}
create temporary view precipitation_summary as
select id, date_trunc('month', date) as month, 
  avg(precipitation) as mean, 
  min(case when precipitation > 0.0 then precipitation end) as min, 
  max(precipitation) as max, 
  sum((precipitation > 0.0)::integer) as "rainy days" 
from precipitation
group by id, month
```
```{sql connection=con}
select * from precipitation_summary
```

This is a great overview table for doing some in-depth analysis of the precipitation distribution. Once you streamed your results into R, a persistant table or any 
kind of text-based file, you can just close the database connection and the two tables _precipitation_ and *precipitation_summary* will be dropped.

```{sql connection=con, output.var="precipitation"}
select month, mean, min, max from precipitation_summary where id=257 order by month ASC
```
```{r}
precipitation %>%
  filter(month >= '1980-01-01' & month < '1990-01-01') %>%
  ggplot(aes(x=month, y=mean)) + 
    geom_ribbon(aes(ymin=min, ymax=max),fill='blue', alpha=0.3) + 
    geom_line(color='blue', size=2)
```

<div class="alert alert-success">Before you continue, play around with these objects a little bit. You should get a good feeling for whether to use temporary object or not
You could for example create another view that holds the exact same information but only for summer rainfalls. This means the date should be in summer and the temperature
 for example above 18°C.
</div>

Now close the connection:

```{r}
dbDisconnect(con)
```

Restablish:

```{r}
# establish the connection
drv <- dbDriver('PostgreSQL')
con <- dbConnect(drv, host='openhydro.de', port=5432, user=getPass('Provide the user'), 
                 password=getPass('Provide the password'), dbname='dwd')
```

And the tables are gone
```{r}
'precipitation' %in% dbListTables(con) | 'precipitation_summary' %in% dbListTables(con)
```


# Joins
## chaining Joins
This section will give some more insights on <span style="color:blue">JOINS</span>. It will cover different types of JOINS and how to chain a JOIN. 
Quite often you will find yourself in a situation, where you have to join a lookup table to a table of interest 
and this lookup table is itself described by another lookup table. 
Querying these structures is fairly straightforward as you can just chain joins together. 
This can be demonstrated by the vegetation_cover table

```{sql connection=con}
select * from stations s
join vegetation_cover vc on st_within(s.geometry, vc.geometry)
join vegetation_cover_description vd on vd.id=vc.description_id 
```

Now, we could join this result to the data table and make all this meta data available to every measurement record. 
This will obviusly take some time. 
In this case you are not interested in the full meta_data record but just in a subset. Of course we want to come up with a fast solution.
<br> Let's build two different Views producing the same output.
```{sql connection=con}
create temporary view join_then_filter as
select d.date, d.value, s.name, v.name as variable, v.unit, vd.name as vegetation from data d
join stations s on s.id=d.id
join variables v on d.variable_id=v.id
join vegetation_cover vc on st_within(s.geometry, vc.geometry)
join vegetation_cover_description vd on vd.id=vc.description_id 
where vd.id=20 and v.id=1 and s.geometry is not null and s.discipline_id=1
```
```{sql connection=con}
create temporary view filter_then_join as
select d.date, d.value, s.name, v.name as variable, v.unit, vd.name as vegetation from data d
join stations s on s.id=d.id and s.discipline_id=1
join variables v on d.variable_id=v.id and v.id=1
join vegetation_cover vc on st_within(s.geometry, vc.geometry) and s.geometry is not null
join vegetation_cover_description vd on vd.id=vc.description_id and vd.id=20
```

Let's have a look on the first two rows of both views:
```{sql connection=con}
select * from join_then_filter limit 2
```
```{sql connection=con}
select * from filter_then_join limit 2
```

<div class="alert alert-warning">Before you continue, what do you think is the faster query and why?</div>

```{sql connection=con}
explain analyze select * from join_then_filter
```
```{sql connection=con}
explain analyze select * from filter_then_join
```

<div class="alert alert-success">Have a close look and don't focus on the total time. The query plan is exactly the same, that means although we were using a different query logic, PostgreSQL kind of got the idea behind our query and tried to find the fastest solution.</div>

## join types


# cleanup
```{r}
dbDisconnect(con)
```