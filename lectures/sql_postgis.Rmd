---
title: "PostGIS"
author: "Mirko Mälicke"
output:
  html_document: 
    toc: yes
    theme: flatly
  html_notebook:
    toc: yes
    theme: flatly
  pdf_document:
    toc: yes
---

```{r, echo=FALSE}
# require the package
if (!("RPostgreSQL" %in% installed.packages())){
  install.packages("RPostgreSQL")
}
if (!("getPass" %in% installed.packages())){
  install.packages("getPass")
}
require(RPostgreSQL)
require(getPass)
require(ggplot2)

# establish the connection
drv <- dbDriver('PostgreSQL')
con <- dbConnect(drv, host='openhydro.de', port=5432, user=getPass('Provide the user'), 
                 password=getPass('Provide the password'), dbname='dwd')
```

### PostGIS

PostGIS is a PostgreSQL extension that offers several new datatypes for attribute declaration along with over 1000 predefined functions.
The main new data type is called 'GEOMETRY' and can store any kind of OGR defined geometry object. 
The most important ones are the 'Point', 'Line' or 'LineString' and 'Polygon' geometry. A new table 'spatial_ref_sys' also created on 
PostGIS creation is prefilled with thousands of different CRS definitions. 
The functions can be used for any kind of spatial and geometrical manipulation and query as known from GIS systems. In fact, 
the PostgreSQL / PostGIS system is a full featured GIS system. <br>
CRS are stored in an ordinary table and can be queried just like you did it in the other lectures:

```{sql connection=con}
select * from spatial_ref_sys limit 5
```

This looks quite simple. There is a srid, the primary key, which you should already know. The creators of PostGIS used the EPSG number 
as primary key. This is very handy as the ESPG identifiers are already unique. (and well known.)<br>
The _proj4text_ field stores the CRS definition as a Poj4 string. This can be understood by most GIS system, like QGis, and recreate 
missing or custom CRS. The _srtext_ field stores the WKT (well known text) definition of the CRS. This could be used to build the CRS 
by hand in other programming languages like Python, Perl or C++. <br>
Ok, then let's see if all coordinate systems we might need are there:
<ul>
<li>unprojected WGS84, as kown from google maps</li>
<li>Pseudo Mercartor, as used by openstreetmap</li>
<li>DHDN, Gauß Krüger Z3, the old offical CRS in Baden-Württemberg</li>
<li>ETRS89 / UTM Z43N, new new official CRS in Baden-Württemberg</li>
</ul>

```{sql connection=con}
select * from spatial_ref_sys where srid in (4326, 3857, 31467, 25832)
```

### Loading spatial data to R

You might have recognized, that RStudio is complaining about a not known datatype when querying the stations table from the database.
This is due to the GEOMETRY data type, we introduced earlier. This is not known by the r package RPostgreSQL. Unlike Python, there 
is no easy way to make R or RStudio understand this datatype. Therefore, we will always have to load the geometries in the WKT format
and convert it in R back to a binary spatial object as supported by the R packages you prefer.<br>
This is where the PostGIS funcitons set in. We can use any of them in <span style="color:blue">SELECT</span> statements or 
<span style="color:blue">WHERE</span> filters. In case you are familiar with the GDAL C++ or Python package, GRASS gis or any other command line based GIS solution, most of the PostGIS functions will be quite familiar to you. Otherwise you will have to search the 
documentation for the correct funciton names and usages.<br>
The WKT of any GEOMETRY object can be loaded with the *ST_AsEWKT* function:

```{sql connection=con}
select id, name, st_asewkt(geometry) from stations limit 5
```

We can see two things here: First, we are able to read the coordinates now. Second, the raw WKT geometry information is prefixed by
an iformation on the used CRS. This is a special PostGIS definition that might not be understood by all other GIS systems. 
The advantage is the ability of the system to store the geometry and CRS information in only one attribute. This also means, that
there is no need to connect this table to the spatial_ref_sys table anymore. We could transform these coordinates on select.

```{sql connection=con}
select id, name, st_asewkt(geometry) as "UTM", st_asewkt(st_transform(geometry, 4326)) as "WGS84" from stations limit 5
```

From here, we have several options to put the geometry information into a more usable format for R. We either load a package that can read WKT. Secondly, we could parse the Strings and extract the needed information ourselves or we could query the information in a
more readable format for R. 

<div class="alert alert-warning">Other languages like Python offer way more powerful bindings to databases. The SQLAlchemy and geoalchemy2 packages in Python, which are available in most scientific Python environments, can load, plot and manipulate PostGIS geometries out of the box.</div>

```{sql connection=con, output.var="stations"}
select id, name, st_x(geometry) as lon, st_y(geometry) as lat from stations where geometry is not null
```
```{r}
ggplot(stations, aes(x=lon, y=lat)) + geom_point(shape=18)
```

### Enabling spatial functions

One of the most important spatial funcitons is PostGIS ability to transform coordinates from and into any coordinate system defined in 
the spatial_ref_sys table. This is extremly helpful, when we want to combine our data with external datasources that force a specific CRS. Secondly, when applying spatial functions and calculating relations, distances or areas we must not use a not suitable CRS 
in order to prevent big calculation mistakes.<br>
PostGIS knows two helpful functions: *ST_Transform* for applying a transformation and *ST_SetCRS* for setting the CRS information in 
case they are missing in the GEOMETRY object.

```{sql connection=con, output.var="stations.wgs84"}
select id, name, st_x(st_transform(geometry, 4326)) as lon, st_y(st_transform(geometry, 4326)) as lat 
  from stations where geometry is not null
```
```{r}
ggplot(stations.wgs84, aes(x=lon, y=lat)) + geom_point(shape=18)
```

It is also possible to calculate distances in the database. Once calculated, these distance can be used like any other attribute, this 
means you can also sort or group by distances. Knowing this, it is for example easy to find the next station for a specific one, or
any arbitraty location.<br>
Let's find the Freiburg stations and search the database for the the closest and farest feature.

```{sql connection=con}
select * from stations where name like '%Freiburg%'
```
```{sql connection=con}
select 
  st_distance(geometry, (select geometry from stations where id=1443)) as distance, 
  * 
from stations 
where id!=1443 and geometry is not null 
order by distance ASC
```
```{sql connection=con}
select 'closest' as description, id, name, distance / 1000 as "distance [km]" from 
(select  st_distance(geometry, (select geometry from stations where id=1443)) as distance, id, name from stations 
where id!=1443 and geometry is not null 
order by distance ASC limit 1) t1
union
select 'farest' as description, id, name, distance / 1000 as "distance [km]" from
(select st_distance(geometry, (select geometry from stations where id=1443)) as distance, id, name from stations 
where id!=1443 and geometry is not null 
order by distance DESC limit 1) t2

```

It is also possible to subset the table and filter the stations to be within a specific distance to the Freiburg station (e.g. 25km).

```{sql connection=con}
select id, name from stations where st_distance(geometry, (select geometry from stations where id=1443)) <= 25000
```
```{sql connection=con}
select id, name from stations where st_within(geometry, st_buffer((select geometry from stations where id=1443), 25000))
```

These two solutions lead to an identical solution, but there is yet happening something very different. It is very good to have different ways of calculating the same result. 
The way PostgreSQL will find the selected features can be described as a query plan. This is esentially, what the computer is planning to do and, more important, why it came to these decisions. Therefore it is a very helpful tool to be able to print out these query plans when trying to identify dropping performances. 
Another helpful information of a query plan is the total runtime on the machine. This does not include the time the data needs to be 
transferred to your computer and the time a client application needs to visualize the data, which is usually the bottleneck but has 
nothing to do with the actual database performance.<br>
In PostgreSQL you can prefix any <span style="color:blue">SELECT</span> statement with <span style="color:blue">EXPLAIN ANALYZE</span>
to make Postgres print out the query plan instead of the results.

```{sql connection=con}
explain analyze select id, name from stations where st_distance(geometry, (select geometry from stations where id=1443)) <= 25000
```
```{sql connection=con}
explain analyze select id, name from stations where st_within(geometry, st_buffer((select geometry from stations where id=1443), 25000))
```

### GIS in the database

The database includes several tables containing data uploaded from the WaBoA (Wasser- und Bodenatlas Baden-Württemberg). 
This is a major source for geodata in the region used by hydrologists quite frequently. Among others, you will find a table called
_vegetation_ cover there. Let's have a look on that table.

```{sql connection=con}
select * from vegetation_cover limit 5
```

The description_id seems to be a foreign key on a lookup table. To get a better insight, join the two tables and load the geometry 
in a human readable way.

```{sql connection=con}
select vc.id, d.name, st_asewkt(vc.geometry) from vegetation_cover vc join vegetation_cover_description d on vc.description_id=d.id limit 5
```

The geometry fields contain Polygons. We could instead use the area.

```{sql connection=con}
select vc.id, d.name, st_area(vc.geometry) from vegetation_cover vc join vegetation_cover_description d on vc.description_id=d.id limit 5
```

Another table from WaBoA is the catchment table (Einzugfsgebiete). These are all 'official' LUBW catchments. Note that these catchments do overlap, as 
they are derived on different levels. 
One thing we could do is join the catchment table to the stations table based on the location. The correct spatial query is a WITHIN or CONTAINS, 
based on which of both geometries you are querying against.

```{sql connection=con}
select * from stations s join einzugsgebiete ezg on st_within(s.geometry, ezg.geometry)
```

If you build your query like this, PostgreSQL will use the first matching feature from the einzugsgebiete table. To verify, that our results are 
correct, we need to count the instances, that do fulfill the connection conditional.

```{sql connection=con}
select s.id, s.name, count(ezg.id) from stations s 
  left outer join einzugsgebiete ezg on st_within(s.geometry, ezg.geometry)
group by s.id, s.name
```


### cleanup
```{r}
dbDisconnect(con)
```


